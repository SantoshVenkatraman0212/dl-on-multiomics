{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:54.827980Z",
     "start_time": "2024-10-16T19:06:53.876322Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.ops.gen_batch_ops import Batch"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:06:53.976588: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 15:06:53.997244: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 15:06:53.997263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 15:06:53.997278: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 15:06:54.001235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 15:06:54.464882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:54.849590Z",
     "start_time": "2024-10-16T19:06:54.831853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_X_train.csv')\n",
    "X_test = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_X_test.csv')\n",
    "X_val = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_X_val.csv')\n",
    "y_train = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_y_train.csv')\n",
    "y_test = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_y_test.csv')\n",
    "y_val = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/5_latent_y_val.csv')\n",
    "\n",
    "X_train.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "X_test.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "X_val.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "y_train.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "y_test.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "y_val.drop('Unnamed: 0', axis = 1, inplace = True)"
   ],
   "id": "d97c5f088213668b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:54.921716Z",
     "start_time": "2024-10-16T19:06:54.919411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of X_val: {X_val.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "print(f'Shape of y_val: {y_val.shape}')"
   ],
   "id": "c5a9ef7b05b48ad8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (203, 5)\n",
      "Shape of X_test: (60, 5)\n",
      "Shape of X_val: (27, 5)\n",
      "Shape of y_train: (203, 1)\n",
      "Shape of y_test: (60, 1)\n",
      "Shape of y_val: (27, 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:54.981682Z",
     "start_time": "2024-10-16T19:06:54.977292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_samples = X_train.shape[0] + X_test.shape[0] + X_val.shape[0]\n",
    "print(f'Train split: {np.round(((X_train.shape[0] / total_samples) * 100), 2)}%')\n",
    "print(f'Validation split: {np.round(((X_val.shape[0] / total_samples) * 100), 2)}%')\n",
    "print(f'Test split: {np.round(((X_test.shape[0] / total_samples) * 100), 2)}%')"
   ],
   "id": "f7f512e993d5b9da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 70.0%\n",
      "Validation split: 9.31%\n",
      "Test split: 20.69%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:55.255355Z",
     "start_time": "2024-10-16T19:06:55.051208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ANN binary classifier\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "input_layer_1 = Input(shape = (X_train.shape[1])) # 2\n",
    "x = Dense(8, activation = 'relu')(input_layer_1)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(4, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "classifier_layer_1 = Dense(1, activation = 'sigmoid')(x)\n",
    "ann_classifier_model_1 = Model(input_layer_1, classifier_layer_1)\n",
    "\n",
    "'''input_layer = Input(shape = (X_train.shape[1])) # 3\n",
    "x = Dense(256, activation = 'relu')(input_layer)\n",
    "x = BatchNormalization(momentum = 0.8)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "classifier_layer = Dense(1, activation = 'sigmoid')(x)\n",
    "ann_classifier_model = Model(input_layer, classifier_layer)'''\n",
    "\n",
    "input_layer_2 = Input(shape = (X_train.shape[1]))\n",
    "y = Dense(32, activation = 'relu')(input_layer_2)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(16, activation = 'relu')(y)\n",
    "y = Dropout(0.25)(y)\n",
    "y = Dense(8, activation = 'relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(4, activation = 'relu')(y)\n",
    "classifier_layer_2 = Dense(1, activation = 'sigmoid')(y)\n",
    "ann_classifier_model_2 = Model(input_layer_2, classifier_layer_2)\n",
    "'''input_layer = Input(shape = (X_train.shape[1]))\n",
    "x = Dense(256, activation = 'relu')(input_layer)\n",
    "x = BatchNormalization(momentum = 0.8)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "classifier_layer = Dense(1, activation = 'sigmoid')(x)\n",
    "ann_classifier_model = Model(input_layer, classifier_layer)'''"
   ],
   "id": "b7a9be18316bb579",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:06:55.088176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.125393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.125520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.126985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.127082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.127136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.170718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.170826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.170888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 15:06:55.170942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1160 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"input_layer = Input(shape = (X_train.shape[1]))\\nx = Dense(256, activation = 'relu')(input_layer)\\nx = BatchNormalization(momentum = 0.8)(x)\\nx = Dropout(0.1)(x)\\nx = Dense(128, activation = 'relu')(x)\\nclassifier_layer = Dense(1, activation = 'sigmoid')(x)\\nann_classifier_model = Model(input_layer, classifier_layer)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Experimentations Done:**\n",
    "\n",
    "1. ANN with I/P layer, Dense_layer(128, relu) and classifier layer val_acc = 69%, train_acc = 70%\n",
    "2. Dense_layer(256, relu) + 1 val_acc = 70.37%, train_acc = 67.49%.\n",
    "3. "
   ],
   "id": "b2b6a4ea6d50f567"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:55.279333Z",
     "start_time": "2024-10-16T19:06:55.267361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "ann_classifier_model_1.compile(loss = BinaryCrossentropy(), optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "ann_classifier_model_2.compile(loss = BinaryCrossentropy(), optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "c487b0e36c7d6b59",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:06:55.335390Z",
     "start_time": "2024-10-16T19:06:55.333260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lrs = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.05, patience = 10, min_lr = 1e-4)\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 10)"
   ],
   "id": "4016f53beb36ce2a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:02.442360Z",
     "start_time": "2024-10-16T19:06:55.383469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "history_ann_1 = ann_classifier_model_1.fit(X_train, y_train, validation_data = (X_val, y_val), callbacks = [lrs, es], epochs = 200)\n"
   ],
   "id": "b283a5b67c95c339",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:06:55.746899: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-16 15:06:56.416075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71164435b0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-16 15:06:56.416094: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-16 15:06:56.418633: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-16 15:06:56.426251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-10-16 15:06:56.475216: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 21ms/step - loss: 0.7849 - accuracy: 0.5025 - val_loss: 0.7704 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7650 - accuracy: 0.4926 - val_loss: 0.7598 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7604 - accuracy: 0.4532 - val_loss: 0.7527 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.4680 - val_loss: 0.7464 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.5025 - val_loss: 0.7408 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7493 - accuracy: 0.4532 - val_loss: 0.7365 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.5025 - val_loss: 0.7331 - val_accuracy: 0.4074 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.4828 - val_loss: 0.7304 - val_accuracy: 0.4074 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7326 - accuracy: 0.5025 - val_loss: 0.7281 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.4877 - val_loss: 0.7262 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.5271 - val_loss: 0.7244 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7050 - accuracy: 0.4975 - val_loss: 0.7229 - val_accuracy: 0.2963 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7299 - accuracy: 0.5025 - val_loss: 0.7215 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5665 - val_loss: 0.7206 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.5468 - val_loss: 0.7193 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.4926 - val_loss: 0.7180 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7041 - accuracy: 0.4926 - val_loss: 0.7166 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7117 - accuracy: 0.4975 - val_loss: 0.7152 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7165 - accuracy: 0.4581 - val_loss: 0.7139 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.5074 - val_loss: 0.7134 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.4778 - val_loss: 0.7127 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7075 - accuracy: 0.5025 - val_loss: 0.7120 - val_accuracy: 0.2593 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5468 - val_loss: 0.7119 - val_accuracy: 0.2963 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.4975 - val_loss: 0.7117 - val_accuracy: 0.2963 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.4532 - val_loss: 0.7113 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7005 - accuracy: 0.4778 - val_loss: 0.7111 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5369 - val_loss: 0.7109 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.5369 - val_loss: 0.7105 - val_accuracy: 0.4074 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5074 - val_loss: 0.7101 - val_accuracy: 0.4074 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.4926 - val_loss: 0.7095 - val_accuracy: 0.4074 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.4631 - val_loss: 0.7090 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5369 - val_loss: 0.7086 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.5369 - val_loss: 0.7081 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.5074 - val_loss: 0.7077 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7102 - accuracy: 0.4581 - val_loss: 0.7074 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5419 - val_loss: 0.7070 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7151 - accuracy: 0.5123 - val_loss: 0.7065 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.4778 - val_loss: 0.7058 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.5025 - val_loss: 0.7054 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7062 - accuracy: 0.4877 - val_loss: 0.7050 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5271 - val_loss: 0.7047 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5419 - val_loss: 0.7043 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7101 - accuracy: 0.4975 - val_loss: 0.7039 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6876 - accuracy: 0.5369 - val_loss: 0.7032 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6946 - accuracy: 0.5172 - val_loss: 0.7028 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.5320 - val_loss: 0.7025 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7021 - accuracy: 0.5025 - val_loss: 0.7024 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.5074 - val_loss: 0.7024 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.4975 - val_loss: 0.7021 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5271 - val_loss: 0.7019 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.4975 - val_loss: 0.7013 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.4877 - val_loss: 0.7011 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.4926 - val_loss: 0.7007 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5074 - val_loss: 0.7002 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7005 - accuracy: 0.4926 - val_loss: 0.7000 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.5025 - val_loss: 0.6998 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6844 - accuracy: 0.5862 - val_loss: 0.6995 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5369 - val_loss: 0.6991 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5813 - val_loss: 0.6987 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.5369 - val_loss: 0.6981 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6990 - accuracy: 0.4926 - val_loss: 0.6977 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5320 - val_loss: 0.6976 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.5419 - val_loss: 0.6973 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.5172 - val_loss: 0.6970 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7015 - accuracy: 0.5172 - val_loss: 0.6966 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5419 - val_loss: 0.6964 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.5222 - val_loss: 0.6962 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6798 - accuracy: 0.5320 - val_loss: 0.6961 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5320 - val_loss: 0.6958 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.5369 - val_loss: 0.6955 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.5222 - val_loss: 0.6951 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.4975 - val_loss: 0.6948 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.5616 - val_loss: 0.6945 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5369 - val_loss: 0.6944 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6831 - accuracy: 0.5369 - val_loss: 0.6943 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.5665 - val_loss: 0.6941 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.5222 - val_loss: 0.6939 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.4828 - val_loss: 0.6939 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.5764 - val_loss: 0.6937 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5419 - val_loss: 0.6935 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6748 - accuracy: 0.5665 - val_loss: 0.6934 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.5320 - val_loss: 0.6932 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.5517 - val_loss: 0.6930 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5862 - val_loss: 0.6925 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6928 - accuracy: 0.5419 - val_loss: 0.6920 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6749 - accuracy: 0.6010 - val_loss: 0.6914 - val_accuracy: 0.5185 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5665 - val_loss: 0.6908 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.5025 - val_loss: 0.6903 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.5369 - val_loss: 0.6900 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5222 - val_loss: 0.6897 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5468 - val_loss: 0.6893 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.5517 - val_loss: 0.6890 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5813 - val_loss: 0.6886 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5616 - val_loss: 0.6885 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.5222 - val_loss: 0.6880 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5714 - val_loss: 0.6876 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5764 - val_loss: 0.6869 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5714 - val_loss: 0.6860 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5369 - val_loss: 0.6855 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5764 - val_loss: 0.6853 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.5714 - val_loss: 0.6850 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.5567 - val_loss: 0.6843 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5714 - val_loss: 0.6840 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.5862 - val_loss: 0.6833 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5616 - val_loss: 0.6827 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5665 - val_loss: 0.6822 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.5567 - val_loss: 0.6819 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5714 - val_loss: 0.6812 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.5517 - val_loss: 0.6806 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5320 - val_loss: 0.6802 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.5567 - val_loss: 0.6797 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5468 - val_loss: 0.6797 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.5222 - val_loss: 0.6796 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5271 - val_loss: 0.6795 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5517 - val_loss: 0.6797 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5714 - val_loss: 0.6791 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.4975 - val_loss: 0.6779 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5369 - val_loss: 0.6774 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.5468 - val_loss: 0.6772 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5369 - val_loss: 0.6770 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.5369 - val_loss: 0.6768 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5369 - val_loss: 0.6772 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.5320 - val_loss: 0.6776 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5369 - val_loss: 0.6775 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5665 - val_loss: 0.6774 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.5961 - val_loss: 0.6771 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.5419 - val_loss: 0.6770 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.5517 - val_loss: 0.6768 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5271 - val_loss: 0.6772 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6108 - val_loss: 0.6770 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.5517 - val_loss: 0.6764 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.5911 - val_loss: 0.6760 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.5419 - val_loss: 0.6755 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5567 - val_loss: 0.6748 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5222 - val_loss: 0.6744 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.5665 - val_loss: 0.6740 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5813 - val_loss: 0.6731 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5369 - val_loss: 0.6724 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5419 - val_loss: 0.6722 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5369 - val_loss: 0.6721 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.5468 - val_loss: 0.6724 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.4926 - val_loss: 0.6730 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5369 - val_loss: 0.6735 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.5419 - val_loss: 0.6736 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6867 - accuracy: 0.5862 - val_loss: 0.6736 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5468 - val_loss: 0.6734 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5616 - val_loss: 0.6731 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.5665 - val_loss: 0.6727 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.5025 - val_loss: 0.6719 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5714 - val_loss: 0.6719 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.5665 - val_loss: 0.6715 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.5468 - val_loss: 0.6707 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.5517 - val_loss: 0.6698 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.5616 - val_loss: 0.6690 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5567 - val_loss: 0.6682 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6819 - accuracy: 0.5369 - val_loss: 0.6676 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.5862 - val_loss: 0.6668 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.6010 - val_loss: 0.6661 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5222 - val_loss: 0.6662 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.6256 - val_loss: 0.6662 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5517 - val_loss: 0.6659 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5665 - val_loss: 0.6654 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.5369 - val_loss: 0.6654 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.4877 - val_loss: 0.6661 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.5419 - val_loss: 0.6667 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6880 - accuracy: 0.5074 - val_loss: 0.6675 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6575 - accuracy: 0.5961 - val_loss: 0.6676 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5320 - val_loss: 0.6680 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5172 - val_loss: 0.6684 - val_accuracy: 0.5926 - lr: 0.0010\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.5714 - val_loss: 0.6684 - val_accuracy: 0.5926 - lr: 0.0010\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5468 - val_loss: 0.6680 - val_accuracy: 0.5926 - lr: 0.0010\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5764 - val_loss: 0.6674 - val_accuracy: 0.6296 - lr: 0.0010\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:04.781722Z",
     "start_time": "2024-10-16T19:07:02.453076Z"
    }
   },
   "cell_type": "code",
   "source": "history_ann_2 = ann_classifier_model_2.fit(X_train, y_train, validation_data = (X_val, y_val), callbacks = [lrs, es], epochs = 200)",
   "id": "e40705e24878951c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 16ms/step - loss: 0.7032 - accuracy: 0.4778 - val_loss: 0.6947 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5074 - val_loss: 0.6944 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5172 - val_loss: 0.6941 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5320 - val_loss: 0.6937 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5123 - val_loss: 0.6934 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5025 - val_loss: 0.6934 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6913 - accuracy: 0.5074 - val_loss: 0.6933 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5222 - val_loss: 0.6933 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.4975 - val_loss: 0.6929 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5123 - val_loss: 0.6927 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.4926 - val_loss: 0.6925 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5123 - val_loss: 0.6924 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5271 - val_loss: 0.6922 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.5123 - val_loss: 0.6922 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5271 - val_loss: 0.6922 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5123 - val_loss: 0.6920 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5172 - val_loss: 0.6918 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6884 - accuracy: 0.5123 - val_loss: 0.6914 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6911 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5123 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5172 - val_loss: 0.6906 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5172 - val_loss: 0.6906 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5172 - val_loss: 0.6906 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5172 - val_loss: 0.6905 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5271 - val_loss: 0.6906 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5172 - val_loss: 0.6907 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5172 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5172 - val_loss: 0.6909 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.5172 - val_loss: 0.6909 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5172 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.5172 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6864 - accuracy: 0.5222 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5172 - val_loss: 0.6908 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5172 - val_loss: 0.6907 - val_accuracy: 0.4815 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:04.917284Z",
     "start_time": "2024-10-16T19:07:04.793473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, tf.round(ann_classifier_model_1.predict(X_test))))"
   ],
   "id": "70897f6eae91b591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.27      0.36        33\n",
      "           1       0.44      0.70      0.54        27\n",
      "\n",
      "    accuracy                           0.47        60\n",
      "   macro avg       0.49      0.49      0.45        60\n",
      "weighted avg       0.49      0.47      0.44        60\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:04.990520Z",
     "start_time": "2024-10-16T19:07:04.928065Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_test, tf.round(ann_classifier_model_2.predict(X_test))))",
   "id": "1ce321632da3ef5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.45      1.00      0.62        27\n",
      "\n",
      "    accuracy                           0.45        60\n",
      "   macro avg       0.23      0.50      0.31        60\n",
      "weighted avg       0.20      0.45      0.28        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanven0212/PycharmProjects/MultiOmicsFYP/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sanven0212/PycharmProjects/MultiOmicsFYP/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/sanven0212/PycharmProjects/MultiOmicsFYP/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.058625Z",
     "start_time": "2024-10-16T19:07:05.000979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using Logistic regression as meta learner\n",
    "y_pred_1 = ann_classifier_model_1.predict(X_val)\n",
    "y_pred_2 = ann_classifier_model_2.predict(X_val)\n",
    "combined_preds = np.column_stack((y_pred_1, y_pred_2))"
   ],
   "id": "e45cad5e5ccba601",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.072756Z",
     "start_time": "2024-10-16T19:07:05.070140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Maxvoting\n",
    "combined_preds"
   ],
   "id": "f7d9fb31ab66e9ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.514397  , 0.5021219 ],\n",
       "       [0.59285146, 0.5141195 ],\n",
       "       [0.57653975, 0.51457626],\n",
       "       [0.49483097, 0.5003954 ],\n",
       "       [0.53136015, 0.50717586],\n",
       "       [0.530031  , 0.50537395],\n",
       "       [0.54245484, 0.5086736 ],\n",
       "       [0.43934622, 0.5003954 ],\n",
       "       [0.4990827 , 0.5003954 ],\n",
       "       [0.591113  , 0.51645637],\n",
       "       [0.4771995 , 0.502283  ],\n",
       "       [0.4710511 , 0.5003954 ],\n",
       "       [0.529516  , 0.503851  ],\n",
       "       [0.5682143 , 0.51584315],\n",
       "       [0.6176096 , 0.52148163],\n",
       "       [0.5248875 , 0.5117376 ],\n",
       "       [0.5232454 , 0.5039897 ],\n",
       "       [0.5483189 , 0.50447077],\n",
       "       [0.5181044 , 0.50341463],\n",
       "       [0.5868371 , 0.52189916],\n",
       "       [0.59015226, 0.5177743 ],\n",
       "       [0.5643534 , 0.5260496 ],\n",
       "       [0.5558926 , 0.515542  ],\n",
       "       [0.5048943 , 0.5024469 ],\n",
       "       [0.4627933 , 0.5007988 ],\n",
       "       [0.59543645, 0.5257413 ],\n",
       "       [0.5281956 , 0.5077129 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.106307Z",
     "start_time": "2024-10-16T19:07:05.103843Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred_1.shape",
   "id": "242492ac116d4d72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.149970Z",
     "start_time": "2024-10-16T19:07:05.143425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "col_dict = {'model_1': tf.squeeze(y_pred_1), 'model_2': tf.squeeze(y_pred_2)}\n",
    "preds_df = pd.DataFrame(col_dict)"
   ],
   "id": "b2c98d22ce20c49e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.192781Z",
     "start_time": "2024-10-16T19:07:05.187494Z"
    }
   },
   "cell_type": "code",
   "source": "preds_df",
   "id": "f8520a62d2daab91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     model_1   model_2\n",
       "0   0.514397  0.502122\n",
       "1   0.592851  0.514120\n",
       "2   0.576540  0.514576\n",
       "3   0.494831  0.500395\n",
       "4   0.531360  0.507176\n",
       "5   0.530031  0.505374\n",
       "6   0.542455  0.508674\n",
       "7   0.439346  0.500395\n",
       "8   0.499083  0.500395\n",
       "9   0.591113  0.516456\n",
       "10  0.477199  0.502283\n",
       "11  0.471051  0.500395\n",
       "12  0.529516  0.503851\n",
       "13  0.568214  0.515843\n",
       "14  0.617610  0.521482\n",
       "15  0.524888  0.511738\n",
       "16  0.523245  0.503990\n",
       "17  0.548319  0.504471\n",
       "18  0.518104  0.503415\n",
       "19  0.586837  0.521899\n",
       "20  0.590152  0.517774\n",
       "21  0.564353  0.526050\n",
       "22  0.555893  0.515542\n",
       "23  0.504894  0.502447\n",
       "24  0.462793  0.500799\n",
       "25  0.595436  0.525741\n",
       "26  0.528196  0.507713"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514397</td>\n",
       "      <td>0.502122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592851</td>\n",
       "      <td>0.514120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.576540</td>\n",
       "      <td>0.514576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494831</td>\n",
       "      <td>0.500395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531360</td>\n",
       "      <td>0.507176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.530031</td>\n",
       "      <td>0.505374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.542455</td>\n",
       "      <td>0.508674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.439346</td>\n",
       "      <td>0.500395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.500395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591113</td>\n",
       "      <td>0.516456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.477199</td>\n",
       "      <td>0.502283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.471051</td>\n",
       "      <td>0.500395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.529516</td>\n",
       "      <td>0.503851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.568214</td>\n",
       "      <td>0.515843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617610</td>\n",
       "      <td>0.521482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.524888</td>\n",
       "      <td>0.511738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.503990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.548319</td>\n",
       "      <td>0.504471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.518104</td>\n",
       "      <td>0.503415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.586837</td>\n",
       "      <td>0.521899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.590152</td>\n",
       "      <td>0.517774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.564353</td>\n",
       "      <td>0.526050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.555893</td>\n",
       "      <td>0.515542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.502447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.462793</td>\n",
       "      <td>0.500799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.595436</td>\n",
       "      <td>0.525741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.528196</td>\n",
       "      <td>0.507713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.258084Z",
     "start_time": "2024-10-16T19:07:05.255480Z"
    }
   },
   "cell_type": "code",
   "source": "preds_df['final_preds'] = (preds_df['model_1'] + preds_df['model_2'])/2",
   "id": "869eef0103b42955",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.311703Z",
     "start_time": "2024-10-16T19:07:05.306236Z"
    }
   },
   "cell_type": "code",
   "source": "preds_df",
   "id": "e482eba84a96fa85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     model_1   model_2  final_preds\n",
       "0   0.514397  0.502122     0.508259\n",
       "1   0.592851  0.514120     0.553486\n",
       "2   0.576540  0.514576     0.545558\n",
       "3   0.494831  0.500395     0.497613\n",
       "4   0.531360  0.507176     0.519268\n",
       "5   0.530031  0.505374     0.517702\n",
       "6   0.542455  0.508674     0.525564\n",
       "7   0.439346  0.500395     0.469871\n",
       "8   0.499083  0.500395     0.499739\n",
       "9   0.591113  0.516456     0.553785\n",
       "10  0.477199  0.502283     0.489741\n",
       "11  0.471051  0.500395     0.485723\n",
       "12  0.529516  0.503851     0.516683\n",
       "13  0.568214  0.515843     0.542029\n",
       "14  0.617610  0.521482     0.569546\n",
       "15  0.524888  0.511738     0.518313\n",
       "16  0.523245  0.503990     0.513618\n",
       "17  0.548319  0.504471     0.526395\n",
       "18  0.518104  0.503415     0.510759\n",
       "19  0.586837  0.521899     0.554368\n",
       "20  0.590152  0.517774     0.553963\n",
       "21  0.564353  0.526050     0.545202\n",
       "22  0.555893  0.515542     0.535717\n",
       "23  0.504894  0.502447     0.503671\n",
       "24  0.462793  0.500799     0.481796\n",
       "25  0.595436  0.525741     0.560589\n",
       "26  0.528196  0.507713     0.517954"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th>final_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514397</td>\n",
       "      <td>0.502122</td>\n",
       "      <td>0.508259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592851</td>\n",
       "      <td>0.514120</td>\n",
       "      <td>0.553486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.576540</td>\n",
       "      <td>0.514576</td>\n",
       "      <td>0.545558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494831</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.497613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531360</td>\n",
       "      <td>0.507176</td>\n",
       "      <td>0.519268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.530031</td>\n",
       "      <td>0.505374</td>\n",
       "      <td>0.517702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.542455</td>\n",
       "      <td>0.508674</td>\n",
       "      <td>0.525564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.439346</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.469871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.499739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591113</td>\n",
       "      <td>0.516456</td>\n",
       "      <td>0.553785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.477199</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>0.489741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.471051</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.485723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.529516</td>\n",
       "      <td>0.503851</td>\n",
       "      <td>0.516683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.568214</td>\n",
       "      <td>0.515843</td>\n",
       "      <td>0.542029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617610</td>\n",
       "      <td>0.521482</td>\n",
       "      <td>0.569546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.524888</td>\n",
       "      <td>0.511738</td>\n",
       "      <td>0.518313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.503990</td>\n",
       "      <td>0.513618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.548319</td>\n",
       "      <td>0.504471</td>\n",
       "      <td>0.526395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.518104</td>\n",
       "      <td>0.503415</td>\n",
       "      <td>0.510759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.586837</td>\n",
       "      <td>0.521899</td>\n",
       "      <td>0.554368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.590152</td>\n",
       "      <td>0.517774</td>\n",
       "      <td>0.553963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.564353</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>0.545202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.555893</td>\n",
       "      <td>0.515542</td>\n",
       "      <td>0.535717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.502447</td>\n",
       "      <td>0.503671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.462793</td>\n",
       "      <td>0.500799</td>\n",
       "      <td>0.481796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.595436</td>\n",
       "      <td>0.525741</td>\n",
       "      <td>0.560589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.528196</td>\n",
       "      <td>0.507713</td>\n",
       "      <td>0.517954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.364396Z",
     "start_time": "2024-10-16T19:07:05.360893Z"
    }
   },
   "cell_type": "code",
   "source": "preds_df['labels'] = preds_df['final_preds'].apply(lambda x: 0 if x <= 0.5 else 1)",
   "id": "8bf3d6fc901c9a44",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.452077Z",
     "start_time": "2024-10-16T19:07:05.446786Z"
    }
   },
   "cell_type": "code",
   "source": "preds_df",
   "id": "c59bd07a5cc553f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     model_1   model_2  final_preds  labels\n",
       "0   0.514397  0.502122     0.508259       1\n",
       "1   0.592851  0.514120     0.553486       1\n",
       "2   0.576540  0.514576     0.545558       1\n",
       "3   0.494831  0.500395     0.497613       0\n",
       "4   0.531360  0.507176     0.519268       1\n",
       "5   0.530031  0.505374     0.517702       1\n",
       "6   0.542455  0.508674     0.525564       1\n",
       "7   0.439346  0.500395     0.469871       0\n",
       "8   0.499083  0.500395     0.499739       0\n",
       "9   0.591113  0.516456     0.553785       1\n",
       "10  0.477199  0.502283     0.489741       0\n",
       "11  0.471051  0.500395     0.485723       0\n",
       "12  0.529516  0.503851     0.516683       1\n",
       "13  0.568214  0.515843     0.542029       1\n",
       "14  0.617610  0.521482     0.569546       1\n",
       "15  0.524888  0.511738     0.518313       1\n",
       "16  0.523245  0.503990     0.513618       1\n",
       "17  0.548319  0.504471     0.526395       1\n",
       "18  0.518104  0.503415     0.510759       1\n",
       "19  0.586837  0.521899     0.554368       1\n",
       "20  0.590152  0.517774     0.553963       1\n",
       "21  0.564353  0.526050     0.545202       1\n",
       "22  0.555893  0.515542     0.535717       1\n",
       "23  0.504894  0.502447     0.503671       1\n",
       "24  0.462793  0.500799     0.481796       0\n",
       "25  0.595436  0.525741     0.560589       1\n",
       "26  0.528196  0.507713     0.517954       1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th>final_preds</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514397</td>\n",
       "      <td>0.502122</td>\n",
       "      <td>0.508259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592851</td>\n",
       "      <td>0.514120</td>\n",
       "      <td>0.553486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.576540</td>\n",
       "      <td>0.514576</td>\n",
       "      <td>0.545558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494831</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.497613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531360</td>\n",
       "      <td>0.507176</td>\n",
       "      <td>0.519268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.530031</td>\n",
       "      <td>0.505374</td>\n",
       "      <td>0.517702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.542455</td>\n",
       "      <td>0.508674</td>\n",
       "      <td>0.525564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.439346</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.469871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.499739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591113</td>\n",
       "      <td>0.516456</td>\n",
       "      <td>0.553785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.477199</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.471051</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.485723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.529516</td>\n",
       "      <td>0.503851</td>\n",
       "      <td>0.516683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.568214</td>\n",
       "      <td>0.515843</td>\n",
       "      <td>0.542029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617610</td>\n",
       "      <td>0.521482</td>\n",
       "      <td>0.569546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.524888</td>\n",
       "      <td>0.511738</td>\n",
       "      <td>0.518313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.503990</td>\n",
       "      <td>0.513618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.548319</td>\n",
       "      <td>0.504471</td>\n",
       "      <td>0.526395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.518104</td>\n",
       "      <td>0.503415</td>\n",
       "      <td>0.510759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.586837</td>\n",
       "      <td>0.521899</td>\n",
       "      <td>0.554368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.590152</td>\n",
       "      <td>0.517774</td>\n",
       "      <td>0.553963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.564353</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>0.545202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.555893</td>\n",
       "      <td>0.515542</td>\n",
       "      <td>0.535717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.502447</td>\n",
       "      <td>0.503671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.462793</td>\n",
       "      <td>0.500799</td>\n",
       "      <td>0.481796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.595436</td>\n",
       "      <td>0.525741</td>\n",
       "      <td>0.560589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.528196</td>\n",
       "      <td>0.507713</td>\n",
       "      <td>0.517954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.507090Z",
     "start_time": "2024-10-16T19:07:05.500004Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_val, preds_df['labels']))",
   "id": "ef132e4df9d47b49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.36      0.50        14\n",
      "           1       0.57      0.92      0.71        13\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.70      0.64      0.60        27\n",
      "weighted avg       0.71      0.63      0.60        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Running tests on the 13 latent features extracted without applying PCA**",
   "id": "f82bde72763fa4dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.606358Z",
     "start_time": "2024-10-16T19:07:05.602253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_13 = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/13_latent_X.csv')\n",
    "y_13 = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/Gleason_Scores.csv')"
   ],
   "id": "3074f7b2de624e7f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:07:05.650877Z",
     "start_time": "2024-10-16T19:07:05.648974Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "72d834194b69481e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
