{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:45.205674Z",
     "start_time": "2024-10-16T22:37:44.256031Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.ops.gen_batch_ops import Batch\n",
    "from tensorflow.keras.regularizers import l1_l2"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 18:37:44.362393: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 18:37:44.383351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 18:37:44.383371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 18:37:44.383385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 18:37:44.387388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 18:37:44.845012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:46.105908Z",
     "start_time": "2024-10-16T22:37:46.044879Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.decomposition import PCA",
   "id": "3d0e75744b1c8199",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:46.839511Z",
     "start_time": "2024-10-16T22:37:46.820719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_combined = pd.read_csv(r'/home/sanven0212/PycharmProjects/MultiOmicsFYP/Combined_Omics_Mutated_Genes_Dataset.csv')\n",
    "df_combined"
   ],
   "id": "5bbd43398fbd5c7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Unnamed: 0  GE_FOXA1  GE_CTNNB1  GE_NKX3-1    GE_ATM   GE_SPOP  GE_ZMYM3  \\\n",
       "0             0  0.602396   0.875180   0.652366  0.725424  0.485713  0.650304   \n",
       "1             1  0.555186   0.384184   0.706125  0.374939  0.384733  0.527966   \n",
       "2             2  0.617020   0.792797   0.481580  0.664329  0.501783  0.696835   \n",
       "3             3  0.478407   0.786356   0.568205  0.838920  0.610479  0.889998   \n",
       "4             4  0.377998   0.824718   0.504132  0.611074  0.470017  0.428205   \n",
       "..          ...       ...        ...        ...       ...       ...       ...   \n",
       "285         285  0.100142   0.781156   0.000000  1.000000  0.346003  0.687155   \n",
       "286         286  0.624984   0.860459   0.753073  0.688023  0.427905  0.716040   \n",
       "287         287  0.642609   0.878522   0.668838  0.722636  0.461165  0.703648   \n",
       "288         288  0.535638   0.851672   0.606659  0.667384  0.350445  0.699619   \n",
       "289         289  0.671103   0.809819   0.773450  0.742236  0.466585  0.871814   \n",
       "\n",
       "      GE_BRAF  CNA_FOXA1  CNA_CTNNB1  ...  MutSig_(Q-value)_TP53  \\\n",
       "0    0.398619   0.351251    0.540445  ...               0.003448   \n",
       "1    0.231899   0.373873    0.699505  ...               0.003448   \n",
       "2    0.373817   0.360982    0.523447  ...               0.003448   \n",
       "3    0.498159   0.356812    0.516999  ...               0.003448   \n",
       "4    0.292625   0.356812    0.519343  ...               0.003448   \n",
       "..        ...        ...         ...  ...                    ...   \n",
       "285  0.230994   0.356812    0.519343  ...               0.003448   \n",
       "286  0.389102   0.356812    0.517585  ...               0.003448   \n",
       "287  0.466096   0.332607    0.467498  ...               0.003448   \n",
       "288  0.382227   0.357739    0.519930  ...               0.003448   \n",
       "289  0.477740   0.351251    0.520516  ...               0.003448   \n",
       "\n",
       "     MutSig_(Q-value)_SPOP  MutSig_(Q-value)_FOXA1  Mut_TP53  Mut_SPOP  \\\n",
       "0                 0.003448                0.003448  0.003448  0.003448   \n",
       "1                 0.003448                0.003448  0.003448  0.003448   \n",
       "2                 0.003448                0.003448  0.003448  0.003448   \n",
       "3                 0.003448                0.003448  0.003448  0.003448   \n",
       "4                 0.003448                0.003448  0.003448  0.003448   \n",
       "..                     ...                     ...       ...       ...   \n",
       "285               0.003448                0.003448  0.003448  0.003448   \n",
       "286               0.003448                0.003448  0.003448  0.003448   \n",
       "287               0.003448                0.003448  0.003448  0.003448   \n",
       "288               0.003448                0.003448  0.003448  0.003448   \n",
       "289               0.003448                0.003448  0.003448  0.003448   \n",
       "\n",
       "     Mut_FOXA1  Freq_TP53  Freq_SPOP  Freq_FOXA1  Gleason_Score  \n",
       "0     0.003448   0.003448   0.003448    0.003448              1  \n",
       "1     0.003448   0.003448   0.003448    0.003448              1  \n",
       "2     0.003448   0.003448   0.003448    0.003448              0  \n",
       "3     0.003448   0.003448   0.003448    0.003448              0  \n",
       "4     0.003448   0.003448   0.003448    0.003448              1  \n",
       "..         ...        ...        ...         ...            ...  \n",
       "285   0.003448   0.003448   0.003448    0.003448              0  \n",
       "286   0.003448   0.003448   0.003448    0.003448              0  \n",
       "287   0.003448   0.003448   0.003448    0.003448              1  \n",
       "288   0.003448   0.003448   0.003448    0.003448              0  \n",
       "289   0.003448   0.003448   0.003448    0.003448              0  \n",
       "\n",
       "[290 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GE_FOXA1</th>\n",
       "      <th>GE_CTNNB1</th>\n",
       "      <th>GE_NKX3-1</th>\n",
       "      <th>GE_ATM</th>\n",
       "      <th>GE_SPOP</th>\n",
       "      <th>GE_ZMYM3</th>\n",
       "      <th>GE_BRAF</th>\n",
       "      <th>CNA_FOXA1</th>\n",
       "      <th>CNA_CTNNB1</th>\n",
       "      <th>...</th>\n",
       "      <th>MutSig_(Q-value)_TP53</th>\n",
       "      <th>MutSig_(Q-value)_SPOP</th>\n",
       "      <th>MutSig_(Q-value)_FOXA1</th>\n",
       "      <th>Mut_TP53</th>\n",
       "      <th>Mut_SPOP</th>\n",
       "      <th>Mut_FOXA1</th>\n",
       "      <th>Freq_TP53</th>\n",
       "      <th>Freq_SPOP</th>\n",
       "      <th>Freq_FOXA1</th>\n",
       "      <th>Gleason_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.875180</td>\n",
       "      <td>0.652366</td>\n",
       "      <td>0.725424</td>\n",
       "      <td>0.485713</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.540445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555186</td>\n",
       "      <td>0.384184</td>\n",
       "      <td>0.706125</td>\n",
       "      <td>0.374939</td>\n",
       "      <td>0.384733</td>\n",
       "      <td>0.527966</td>\n",
       "      <td>0.231899</td>\n",
       "      <td>0.373873</td>\n",
       "      <td>0.699505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.617020</td>\n",
       "      <td>0.792797</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.501783</td>\n",
       "      <td>0.696835</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.523447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.478407</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.838920</td>\n",
       "      <td>0.610479</td>\n",
       "      <td>0.889998</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.516999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.377998</td>\n",
       "      <td>0.824718</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.611074</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.428205</td>\n",
       "      <td>0.292625</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>0.100142</td>\n",
       "      <td>0.781156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.230994</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>0.624984</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.688023</td>\n",
       "      <td>0.427905</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.389102</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.517585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>0.642609</td>\n",
       "      <td>0.878522</td>\n",
       "      <td>0.668838</td>\n",
       "      <td>0.722636</td>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.703648</td>\n",
       "      <td>0.466096</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>0.535638</td>\n",
       "      <td>0.851672</td>\n",
       "      <td>0.606659</td>\n",
       "      <td>0.667384</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>0.699619</td>\n",
       "      <td>0.382227</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>0.671103</td>\n",
       "      <td>0.809819</td>\n",
       "      <td>0.773450</td>\n",
       "      <td>0.742236</td>\n",
       "      <td>0.466585</td>\n",
       "      <td>0.871814</td>\n",
       "      <td>0.477740</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:48.137781Z",
     "start_time": "2024-10-16T22:37:48.127589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_combined.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df_combined"
   ],
   "id": "4952e000c86a2261",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     GE_FOXA1  GE_CTNNB1  GE_NKX3-1    GE_ATM   GE_SPOP  GE_ZMYM3   GE_BRAF  \\\n",
       "0    0.602396   0.875180   0.652366  0.725424  0.485713  0.650304  0.398619   \n",
       "1    0.555186   0.384184   0.706125  0.374939  0.384733  0.527966  0.231899   \n",
       "2    0.617020   0.792797   0.481580  0.664329  0.501783  0.696835  0.373817   \n",
       "3    0.478407   0.786356   0.568205  0.838920  0.610479  0.889998  0.498159   \n",
       "4    0.377998   0.824718   0.504132  0.611074  0.470017  0.428205  0.292625   \n",
       "..        ...        ...        ...       ...       ...       ...       ...   \n",
       "285  0.100142   0.781156   0.000000  1.000000  0.346003  0.687155  0.230994   \n",
       "286  0.624984   0.860459   0.753073  0.688023  0.427905  0.716040  0.389102   \n",
       "287  0.642609   0.878522   0.668838  0.722636  0.461165  0.703648  0.466096   \n",
       "288  0.535638   0.851672   0.606659  0.667384  0.350445  0.699619  0.382227   \n",
       "289  0.671103   0.809819   0.773450  0.742236  0.466585  0.871814  0.477740   \n",
       "\n",
       "     CNA_FOXA1  CNA_CTNNB1  CNA_PTEN  ...  MutSig_(Q-value)_TP53  \\\n",
       "0     0.351251    0.540445  0.683951  ...               0.003448   \n",
       "1     0.373873    0.699505  0.410377  ...               0.003448   \n",
       "2     0.360982    0.523447  0.553580  ...               0.003448   \n",
       "3     0.356812    0.516999  0.644938  ...               0.003448   \n",
       "4     0.356812    0.519343  0.635062  ...               0.003448   \n",
       "..         ...         ...       ...  ...                    ...   \n",
       "285   0.356812    0.519343  0.637037  ...               0.003448   \n",
       "286   0.356812    0.517585  0.639506  ...               0.003448   \n",
       "287   0.332607    0.467498  0.612923  ...               0.003448   \n",
       "288   0.357739    0.519930  0.644444  ...               0.003448   \n",
       "289   0.351251    0.520516  0.610370  ...               0.003448   \n",
       "\n",
       "     MutSig_(Q-value)_SPOP  MutSig_(Q-value)_FOXA1  Mut_TP53  Mut_SPOP  \\\n",
       "0                 0.003448                0.003448  0.003448  0.003448   \n",
       "1                 0.003448                0.003448  0.003448  0.003448   \n",
       "2                 0.003448                0.003448  0.003448  0.003448   \n",
       "3                 0.003448                0.003448  0.003448  0.003448   \n",
       "4                 0.003448                0.003448  0.003448  0.003448   \n",
       "..                     ...                     ...       ...       ...   \n",
       "285               0.003448                0.003448  0.003448  0.003448   \n",
       "286               0.003448                0.003448  0.003448  0.003448   \n",
       "287               0.003448                0.003448  0.003448  0.003448   \n",
       "288               0.003448                0.003448  0.003448  0.003448   \n",
       "289               0.003448                0.003448  0.003448  0.003448   \n",
       "\n",
       "     Mut_FOXA1  Freq_TP53  Freq_SPOP  Freq_FOXA1  Gleason_Score  \n",
       "0     0.003448   0.003448   0.003448    0.003448              1  \n",
       "1     0.003448   0.003448   0.003448    0.003448              1  \n",
       "2     0.003448   0.003448   0.003448    0.003448              0  \n",
       "3     0.003448   0.003448   0.003448    0.003448              0  \n",
       "4     0.003448   0.003448   0.003448    0.003448              1  \n",
       "..         ...        ...        ...         ...            ...  \n",
       "285   0.003448   0.003448   0.003448    0.003448              0  \n",
       "286   0.003448   0.003448   0.003448    0.003448              0  \n",
       "287   0.003448   0.003448   0.003448    0.003448              1  \n",
       "288   0.003448   0.003448   0.003448    0.003448              0  \n",
       "289   0.003448   0.003448   0.003448    0.003448              0  \n",
       "\n",
       "[290 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GE_FOXA1</th>\n",
       "      <th>GE_CTNNB1</th>\n",
       "      <th>GE_NKX3-1</th>\n",
       "      <th>GE_ATM</th>\n",
       "      <th>GE_SPOP</th>\n",
       "      <th>GE_ZMYM3</th>\n",
       "      <th>GE_BRAF</th>\n",
       "      <th>CNA_FOXA1</th>\n",
       "      <th>CNA_CTNNB1</th>\n",
       "      <th>CNA_PTEN</th>\n",
       "      <th>...</th>\n",
       "      <th>MutSig_(Q-value)_TP53</th>\n",
       "      <th>MutSig_(Q-value)_SPOP</th>\n",
       "      <th>MutSig_(Q-value)_FOXA1</th>\n",
       "      <th>Mut_TP53</th>\n",
       "      <th>Mut_SPOP</th>\n",
       "      <th>Mut_FOXA1</th>\n",
       "      <th>Freq_TP53</th>\n",
       "      <th>Freq_SPOP</th>\n",
       "      <th>Freq_FOXA1</th>\n",
       "      <th>Gleason_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.875180</td>\n",
       "      <td>0.652366</td>\n",
       "      <td>0.725424</td>\n",
       "      <td>0.485713</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.540445</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555186</td>\n",
       "      <td>0.384184</td>\n",
       "      <td>0.706125</td>\n",
       "      <td>0.374939</td>\n",
       "      <td>0.384733</td>\n",
       "      <td>0.527966</td>\n",
       "      <td>0.231899</td>\n",
       "      <td>0.373873</td>\n",
       "      <td>0.699505</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617020</td>\n",
       "      <td>0.792797</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.501783</td>\n",
       "      <td>0.696835</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.523447</td>\n",
       "      <td>0.553580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478407</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.838920</td>\n",
       "      <td>0.610479</td>\n",
       "      <td>0.889998</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.516999</td>\n",
       "      <td>0.644938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377998</td>\n",
       "      <td>0.824718</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.611074</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.428205</td>\n",
       "      <td>0.292625</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.635062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.100142</td>\n",
       "      <td>0.781156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.230994</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.624984</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.688023</td>\n",
       "      <td>0.427905</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.389102</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.517585</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.642609</td>\n",
       "      <td>0.878522</td>\n",
       "      <td>0.668838</td>\n",
       "      <td>0.722636</td>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.703648</td>\n",
       "      <td>0.466096</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.535638</td>\n",
       "      <td>0.851672</td>\n",
       "      <td>0.606659</td>\n",
       "      <td>0.667384</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>0.699619</td>\n",
       "      <td>0.382227</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.671103</td>\n",
       "      <td>0.809819</td>\n",
       "      <td>0.773450</td>\n",
       "      <td>0.742236</td>\n",
       "      <td>0.466585</td>\n",
       "      <td>0.871814</td>\n",
       "      <td>0.477740</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.610370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Checking the correlation between I/P features and Target**",
   "id": "fa647c3ea40cb05c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:50.352702Z",
     "start_time": "2024-10-16T22:37:50.348670Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Correlation of input features and target: {df_combined.corr()['Gleason_Score'].sort_values(ascending = False)}\")",
   "id": "f03b677ef747f13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of input features and target: Gleason_Score             1.000000\n",
      "CNA_BRAF                  0.217880\n",
      "DM_SPOP                   0.200400\n",
      "CNA_CTNNB1                0.184626\n",
      "CNA_FOXA1                 0.096956\n",
      "CNA_ZMYM3                 0.095829\n",
      "GE_BRAF                   0.071645\n",
      "DM_CTNNB1                 0.063715\n",
      "GE_FOXA1                  0.058571\n",
      "CNA_MED12                 0.037322\n",
      "DM_PTEN                   0.033545\n",
      "CNA_TP53                  0.021447\n",
      "DM_FOXA1                  0.004920\n",
      "DM_BRAF                   0.004415\n",
      "GE_NKX3-1                -0.002475\n",
      "DM_NKX3-1                -0.035855\n",
      "CNA_PTEN                 -0.044222\n",
      "GE_ATM                   -0.099585\n",
      "GE_CTNNB1                -0.104855\n",
      "CNA_SPOP                 -0.108612\n",
      "GE_ZMYM3                 -0.134176\n",
      "GE_SPOP                  -0.220804\n",
      "CNA_ATM                  -0.225144\n",
      "MutSig_(Q-value)_TP53          NaN\n",
      "MutSig_(Q-value)_SPOP          NaN\n",
      "MutSig_(Q-value)_FOXA1         NaN\n",
      "Mut_TP53                       NaN\n",
      "Mut_SPOP                       NaN\n",
      "Mut_FOXA1                      NaN\n",
      "Freq_TP53                      NaN\n",
      "Freq_SPOP                      NaN\n",
      "Freq_FOXA1                     NaN\n",
      "Name: Gleason_Score, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:51.747827Z",
     "start_time": "2024-10-16T22:37:51.742725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Essential features\n",
    "#Having corr values > 0.2\n",
    "df_correlations = df_combined.corr()['Gleason_Score'] \n",
    "essential_features = df_correlations[abs(df_correlations) > 0.2]\n",
    "essential_features"
   ],
   "id": "ad8d9ab04a0a728",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GE_SPOP         -0.220804\n",
       "CNA_ATM         -0.225144\n",
       "CNA_BRAF         0.217880\n",
       "DM_SPOP          0.200400\n",
       "Gleason_Score    1.000000\n",
       "Name: Gleason_Score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:53.545466Z",
     "start_time": "2024-10-16T22:37:53.538639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using Only these features for binary classification\n",
    "df_demo = df_combined[['GE_SPOP', 'CNA_ATM', 'CNA_BRAF', 'DM_SPOP', 'Gleason_Score']]\n",
    "df_demo"
   ],
   "id": "94366ceca3820add",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      GE_SPOP   CNA_ATM  CNA_BRAF   DM_SPOP  Gleason_Score\n",
       "0    0.485713  0.667240  0.235960  0.812676              1\n",
       "1    0.384733  0.491585  0.245381  0.847404              1\n",
       "2    0.501783  0.559380  0.205286  0.522828              0\n",
       "3    0.610479  0.554217  0.204578  0.725606              0\n",
       "4    0.470017  0.559380  0.205757  0.683042              1\n",
       "..        ...       ...       ...       ...            ...\n",
       "285  0.346003  0.554217  0.204578  0.691388              0\n",
       "286  0.427905  0.555364  0.204814  0.768633              0\n",
       "287  0.461165  0.441728  0.222167  0.727267              1\n",
       "288  0.350445  0.558233  0.203870  0.835168              0\n",
       "289  0.466585  0.557085  0.205286  0.922994              0\n",
       "\n",
       "[290 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GE_SPOP</th>\n",
       "      <th>CNA_ATM</th>\n",
       "      <th>CNA_BRAF</th>\n",
       "      <th>DM_SPOP</th>\n",
       "      <th>Gleason_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485713</td>\n",
       "      <td>0.667240</td>\n",
       "      <td>0.235960</td>\n",
       "      <td>0.812676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384733</td>\n",
       "      <td>0.491585</td>\n",
       "      <td>0.245381</td>\n",
       "      <td>0.847404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501783</td>\n",
       "      <td>0.559380</td>\n",
       "      <td>0.205286</td>\n",
       "      <td>0.522828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.610479</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.204578</td>\n",
       "      <td>0.725606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.559380</td>\n",
       "      <td>0.205757</td>\n",
       "      <td>0.683042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.204578</td>\n",
       "      <td>0.691388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.427905</td>\n",
       "      <td>0.555364</td>\n",
       "      <td>0.204814</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.441728</td>\n",
       "      <td>0.222167</td>\n",
       "      <td>0.727267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.350445</td>\n",
       "      <td>0.558233</td>\n",
       "      <td>0.203870</td>\n",
       "      <td>0.835168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.466585</td>\n",
       "      <td>0.557085</td>\n",
       "      <td>0.205286</td>\n",
       "      <td>0.922994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:54.886470Z",
     "start_time": "2024-10-16T22:37:54.879807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_demo.drop('Gleason_Score', axis = 1)\n",
    "y = df_demo['Gleason_Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.33, random_state = 42)"
   ],
   "id": "7aecf9247ef59cd9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:56.066497Z",
     "start_time": "2024-10-16T22:37:56.059695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ],
   "id": "8b9337bb7f61ec22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:57.384014Z",
     "start_time": "2024-10-16T22:37:57.372966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, lr.predict(X_val)))"
   ],
   "id": "18fd3244d8d20fc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.47      0.58        15\n",
      "           1       0.60      0.86      0.71        14\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.69      0.66      0.64        29\n",
      "weighted avg       0.69      0.66      0.64        29\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:37:58.660717Z",
     "start_time": "2024-10-16T22:37:58.647630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "print(classification_report(y_val, svc.predict(X_val)))"
   ],
   "id": "8f1ffb189823126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.27      0.40        15\n",
      "           1       0.54      0.93      0.68        14\n",
      "\n",
      "    accuracy                           0.59        29\n",
      "   macro avg       0.67      0.60      0.54        29\n",
      "weighted avg       0.68      0.59      0.54        29\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:38:01.331793Z",
     "start_time": "2024-10-16T22:38:01.115180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_layer = Input(shape = (X_train.shape[1], ))\n",
    "x = Dense(32, activation = 'relu')(input_layer)\n",
    "x = Dense(16, activation = 'relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(8, activation = 'relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output_layer = Dense(1, activation = 'sigmoid')(x)\n",
    "ann_model = Model(input_layer, output_layer)\n",
    "ann_model.summary()"
   ],
   "id": "6d3ad2afd5ebcd48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833 (3.25 KB)\n",
      "Trainable params: 833 (3.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 18:38:01.167523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.205891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.206052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.208329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.208434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.208497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.267847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.267964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.268036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 18:38:01.268094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1160 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:38:05.224794Z",
     "start_time": "2024-10-16T22:38:05.216447Z"
    }
   },
   "cell_type": "code",
   "source": "ann_model.compile(loss = BinaryCrossentropy(), optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])",
   "id": "c566d32823f1fe55",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:38:05.868999Z",
     "start_time": "2024-10-16T22:38:05.866181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lrs = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.00001, patience = 10, min_lr = 1e-6)\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 10)"
   ],
   "id": "5d8dfbf3cd7d6d9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T22:38:11.780324Z",
     "start_time": "2024-10-16T22:38:06.841630Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = ann_model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, callbacks = [lrs])",
   "id": "efa8cde560e76c54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 18:38:07.233115: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-16 18:38:07.975210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7d026d224870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-16 18:38:07.975230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-16 18:38:07.977878: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-16 18:38:07.985190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-10-16 18:38:08.034471: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 20ms/step - loss: 0.6979 - accuracy: 0.4631 - val_loss: 0.6965 - val_accuracy: 0.4483 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5419 - val_loss: 0.6952 - val_accuracy: 0.4483 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5074 - val_loss: 0.6950 - val_accuracy: 0.4483 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5567 - val_loss: 0.6950 - val_accuracy: 0.4483 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5813 - val_loss: 0.6939 - val_accuracy: 0.4828 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.6108 - val_loss: 0.6931 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.6059 - val_loss: 0.6930 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6771 - accuracy: 0.5764 - val_loss: 0.6928 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.5764 - val_loss: 0.6914 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6158 - val_loss: 0.6884 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6776 - accuracy: 0.5714 - val_loss: 0.6883 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6776 - accuracy: 0.5665 - val_loss: 0.6872 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.5813 - val_loss: 0.6843 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6207 - val_loss: 0.6831 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.5714 - val_loss: 0.6811 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.6256 - val_loss: 0.6788 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6647 - accuracy: 0.6256 - val_loss: 0.6796 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.5961 - val_loss: 0.6814 - val_accuracy: 0.5345 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.6256 - val_loss: 0.6887 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5764 - val_loss: 0.6901 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.5911 - val_loss: 0.6846 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6595 - accuracy: 0.5567 - val_loss: 0.6775 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.6059 - val_loss: 0.6781 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6059 - val_loss: 0.6839 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.6158 - val_loss: 0.6871 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.5911 - val_loss: 0.6869 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6355 - val_loss: 0.6770 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5665 - val_loss: 0.6722 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.5911 - val_loss: 0.6704 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6453 - val_loss: 0.6753 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6601 - val_loss: 0.6806 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6517 - accuracy: 0.6207 - val_loss: 0.6804 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6454 - accuracy: 0.6453 - val_loss: 0.6813 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6010 - val_loss: 0.6745 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6448 - accuracy: 0.6404 - val_loss: 0.6731 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.6502 - val_loss: 0.6717 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6158 - val_loss: 0.6754 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.5961 - val_loss: 0.6739 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.6207 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6502 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6207 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6207 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6108 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6207 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6290 - accuracy: 0.6502 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6502 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6355 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6207 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6010 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.5961 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.5911 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.6108 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6601 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6010 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6108 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6256 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6552 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.6305 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6404 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6457 - accuracy: 0.6552 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6391 - accuracy: 0.6650 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6445 - accuracy: 0.6355 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6473 - accuracy: 0.6108 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6453 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6108 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6355 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6355 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.5961 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6404 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6502 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6059 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6552 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6158 - val_loss: 0.6752 - val_accuracy: 0.5862 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:40:52.715593Z",
     "start_time": "2024-10-16T23:40:51.438192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 2000)\n",
    "rfc.fit(X_train, y_train)\n",
    "print(classification_report(y_val, rfc.predict(X_val)))"
   ],
   "id": "888aee00f07d9fdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.53      0.64        15\n",
      "           1       0.63      0.86      0.73        14\n",
      "\n",
      "    accuracy                           0.69        29\n",
      "   macro avg       0.72      0.70      0.68        29\n",
      "weighted avg       0.72      0.69      0.68        29\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **PCA**",
   "id": "b542ff3da8520527"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:06.647481Z",
     "start_time": "2024-10-16T18:54:06.628791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components = None)\n",
    "pca.fit(df_combined.drop('Gleason_Score', axis = 1))\n",
    "evr = pca.explained_variance_ratio_\n",
    "cevr = np.cumsum(evr)"
   ],
   "id": "f90167b15427a990",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:07.229514Z",
     "start_time": "2024-10-16T18:54:07.225026Z"
    }
   },
   "cell_type": "code",
   "source": "evr",
   "id": "bad676681faf9ff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.13643242e-01, 1.94314970e-01, 1.12140150e-01, 6.83658484e-02,\n",
       "       5.85743720e-02, 4.61273941e-02, 4.18706716e-02, 3.69781801e-02,\n",
       "       3.37460340e-02, 2.91330479e-02, 2.73940104e-02, 2.33988728e-02,\n",
       "       2.15159809e-02, 1.80799931e-02, 1.48409515e-02, 1.35103872e-02,\n",
       "       1.13587241e-02, 9.72222803e-03, 8.81336614e-03, 8.20053291e-03,\n",
       "       6.65578746e-03, 1.61525466e-03, 1.19464556e-33, 1.19464556e-33,\n",
       "       1.19464556e-33, 1.19464556e-33, 1.19464556e-33, 1.19464556e-33,\n",
       "       1.19464556e-33, 1.19464556e-33, 1.19464556e-33])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:07.717109Z",
     "start_time": "2024-10-16T18:54:07.713728Z"
    }
   },
   "cell_type": "code",
   "source": "len(evr)",
   "id": "18fc5384ff174722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:08.310826Z",
     "start_time": "2024-10-16T18:54:08.193995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(range(1, len(cevr) + 1), cevr, color = 'b', marker = 'o')\n",
    "plt.title('No of Principal Components VS Cumulative Explained Variance Ratio')\n",
    "plt.xlabel('No of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')"
   ],
   "id": "42f28b7a46668be6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative Explained Variance Ratio')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note: From the above code it is evident that around half of the features can be removed since just retaining around 12 features preserves almost 90% of the variance.**",
   "id": "54a387adb86301d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:09.435874Z",
     "start_time": "2024-10-16T18:54:09.429026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Determining the exact no of features that capture 90% of the variance\n",
    "X = df_combined.drop('Gleason_Score', axis = 1)\n",
    "pca_1 = PCA(n_components = 0.9).fit(X)\n",
    "print(f'No of components that capture 90% of the variance: {pca_1.n_components_}')"
   ],
   "id": "856afafb2a6fc4fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of components that capture 90% of the variance: 13\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:10.045799Z",
     "start_time": "2024-10-16T18:54:09.947855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Checking the elbow curve for the pca explained variance for entire dataset\n",
    "ev = pca.explained_variance_\n",
    "plt.plot(range(1, len(ev) + 1), ev, marker = 'o', color = 'b')\n",
    "plt.title('Elbow Curve for Explained Variance')\n",
    "plt.xlabel('No of Principal Components')\n",
    "plt.ylabel('Explained Variance')"
   ],
   "id": "9d0113c5b0105755",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained Variance')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**The elbow point for the curve is around the 5 principal component mark. However since, we want to preserve atleast 90% of the variance of the dataset. We will be going with 13 principal components**",
   "id": "afb9b1ea2d407398"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:11.094070Z",
     "start_time": "2024-10-16T18:54:11.089480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca_2 = PCA(n_components = 13)\n",
    "X_pca = pca_2.fit_transform(X)"
   ],
   "id": "e0feb2d7c106cd99",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:11.713979Z",
     "start_time": "2024-10-16T18:54:11.709964Z"
    }
   },
   "cell_type": "code",
   "source": "X_pca",
   "id": "d086675b55a2c555",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03915129,  0.25591064, -0.02462468, ..., -0.16029406,\n",
       "         0.0226977 , -0.00068658],\n",
       "       [-0.5633726 , -0.10213798, -0.05474524, ...,  0.02349427,\n",
       "        -0.04247905,  0.01655767],\n",
       "       [ 0.3919805 , -0.02780241, -0.01497065, ...,  0.03296212,\n",
       "         0.01104759, -0.04374397],\n",
       "       ...,\n",
       "       [ 0.41940482,  0.15114141,  0.0469614 , ..., -0.01203577,\n",
       "         0.00685298,  0.16842272],\n",
       "       [ 0.02223373,  0.14428133,  0.12941417, ..., -0.01338233,\n",
       "         0.11233086,  0.03091502],\n",
       "       [-0.08598788,  0.40875558,  0.19965279, ...,  0.06390673,\n",
       "         0.004993  ,  0.03752816]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:12.804055Z",
     "start_time": "2024-10-16T18:54:12.800632Z"
    }
   },
   "cell_type": "code",
   "source": "X_pca.shape",
   "id": "a522fcb8819a6620",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:54:13.488751Z",
     "start_time": "2024-10-16T18:54:13.484599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = df_combined['Gleason_Score']\n",
    "y"
   ],
   "id": "f8340b726f6bf952",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "285    0\n",
       "286    0\n",
       "287    1\n",
       "288    0\n",
       "289    0\n",
       "Name: Gleason_Score, Length: 290, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Autoencoders**",
   "id": "372e792785f35fea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:55:31.889360Z",
     "start_time": "2024-10-16T18:55:31.566320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Vanilla Autocomplete autoencoder\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "input_dim = X_pca.shape[1]\n",
    "encoding_dim = 5\n",
    "en_input = Input(shape = (input_dim, ))\n",
    "en_layer = Dense(encoding_dim, activation = 'relu')(en_input)\n",
    "de_layer = Dense(input_dim, activation = 'sigmoid')(en_layer)\n",
    "auto_encoder_model = Model(en_input, de_layer)\n",
    "auto_encoder_model.summary()"
   ],
   "id": "98b420bd507fd278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 70        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 13)                78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148 (592.00 Byte)\n",
      "Trainable params: 148 (592.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 14:55:31.627957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.740539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.740719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.742666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.742815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.742927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.799452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.799556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.799627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-16 14:55:31.799680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6257 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:55:33.047102Z",
     "start_time": "2024-10-16T18:55:33.037800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "auto_encoder_model.compile(loss = mean_squared_error, optimizer = Adam(learning_rate = 0.001))"
   ],
   "id": "75845a98d2cb2c9b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Callbacks for the autoencoder model**",
   "id": "bd91036e362ada68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:55:34.902016Z",
     "start_time": "2024-10-16T18:55:34.899113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lrs = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.05, patience = 10, min_lr = 1e-4)\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 10)"
   ],
   "id": "9c79b4005b28f103",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:03.960185Z",
     "start_time": "2024-10-16T18:55:35.537233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Fitting the model on the pca transformed dataset\n",
    "history_1 = auto_encoder_model.fit(X_pca, X_pca, validation_split = 0.2, callbacks = [lrs, es], epochs = 1000)"
   ],
   "id": "510adeef38551bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 14:55:35.888813: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-16 14:55:36.254675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ae614443790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-16 14:55:36.254691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-16 14:55:36.258729: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-16 14:55:36.271097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-10-16 14:55:36.324368: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 16ms/step - loss: 0.2697 - val_loss: 0.2738 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2669 - val_loss: 0.2708 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2640 - val_loss: 0.2677 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2610 - val_loss: 0.2644 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2578 - val_loss: 0.2610 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2544 - val_loss: 0.2575 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2510 - val_loss: 0.2537 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2473 - val_loss: 0.2499 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2434 - val_loss: 0.2458 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2394 - val_loss: 0.2416 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2372 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2307 - val_loss: 0.2325 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2260 - val_loss: 0.2277 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2211 - val_loss: 0.2226 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2161 - val_loss: 0.2175 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2109 - val_loss: 0.2122 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2055 - val_loss: 0.2068 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2000 - val_loss: 0.2012 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 0.1956 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1886 - val_loss: 0.1899 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1829 - val_loss: 0.1842 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1771 - val_loss: 0.1784 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1712 - val_loss: 0.1727 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1654 - val_loss: 0.1669 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1595 - val_loss: 0.1613 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1537 - val_loss: 0.1556 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1480 - val_loss: 0.1500 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1424 - val_loss: 0.1445 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1368 - val_loss: 0.1391 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1314 - val_loss: 0.1338 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1262 - val_loss: 0.1287 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.1238 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1161 - val_loss: 0.1190 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1113 - val_loss: 0.1144 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1067 - val_loss: 0.1099 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1023 - val_loss: 0.1057 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0981 - val_loss: 0.1016 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0940 - val_loss: 0.0977 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.0939 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0865 - val_loss: 0.0904 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0870 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0838 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.0808 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0736 - val_loss: 0.0779 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0708 - val_loss: 0.0752 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0726 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0657 - val_loss: 0.0702 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.0679 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0657 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0636 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0617 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0599 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0582 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0566 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0503 - val_loss: 0.0550 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0489 - val_loss: 0.0536 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0475 - val_loss: 0.0523 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.0510 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0451 - val_loss: 0.0498 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0487 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0476 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0466 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0457 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0448 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.0440 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0385 - val_loss: 0.0433 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0378 - val_loss: 0.0425 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0371 - val_loss: 0.0418 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0364 - val_loss: 0.0412 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0359 - val_loss: 0.0406 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.0400 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0394 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0389 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0384 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0380 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0375 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0371 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0367 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0313 - val_loss: 0.0359 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0310 - val_loss: 0.0356 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0353 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0349 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0346 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0343 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0341 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0338 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0336 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0333 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0331 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0328 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0326 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0324 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0322 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0321 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0319 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0317 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0315 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0314 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0312 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0311 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0309 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0307 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0305 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0304 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0303 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0302 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0301 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0299 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0298 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0297 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0296 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0295 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0294 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0294 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0293 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0292 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0291 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0290 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0289 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0289 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0288 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0287 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0286 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0286 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0285 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0284 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0284 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0283 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 0.0283 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 0.0282 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0281 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0281 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0280 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0280 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0278 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0278 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0237 - val_loss: 0.0277 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0277 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0276 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0276 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0275 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0275 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0274 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0273 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0273 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0272 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0272 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0271 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0271 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0271 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0270 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0270 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0269 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0269 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0269 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0268 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0268 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0268 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0267 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0267 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0267 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0266 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0266 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0266 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0265 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0264 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0264 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0263 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0262 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0262 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0262 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0261 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0261 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0261 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0260 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0260 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0260 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0258 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0258 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0258 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0255 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0255 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0255 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0255 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0253 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0253 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0253 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0252 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0250 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0250 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0250 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0250 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0249 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0249 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0249 - lr: 0.0010\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0248 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0247 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0246 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0246 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0246 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0246 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0245 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0245 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0245 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0244 - lr: 0.0010\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0243 - lr: 0.0010\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0242 - lr: 0.0010\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0241 - lr: 0.0010\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0241 - lr: 0.0010\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0241 - lr: 0.0010\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0241 - lr: 0.0010\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0239 - lr: 0.0010\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0239 - lr: 0.0010\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0239 - lr: 0.0010\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0239 - lr: 0.0010\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0236 - lr: 0.0010\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0235 - lr: 0.0010\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0234 - lr: 0.0010\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0233 - lr: 0.0010\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0232 - lr: 0.0010\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0231 - lr: 0.0010\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0229 - lr: 0.0010\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0228 - lr: 0.0010\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0227 - lr: 0.0010\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0225 - lr: 0.0010\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0224 - lr: 0.0010\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0221 - lr: 0.0010\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0219 - lr: 0.0010\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0217 - lr: 0.0010\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0214 - lr: 0.0010\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 0.0010\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0207 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:21.069240Z",
     "start_time": "2024-10-16T18:56:20.978314Z"
    }
   },
   "cell_type": "code",
   "source": "X_latent = auto_encoder_model.predict(X_pca)",
   "id": "738898d1e1e44d80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:21.957062Z",
     "start_time": "2024-10-16T18:56:21.953823Z"
    }
   },
   "cell_type": "code",
   "source": "X_latent",
   "id": "579a087e55b11ece",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01893338, 0.17223285, 0.06807644, ..., 0.0095825 , 0.0090329 ,\n",
       "        0.00890377],\n",
       "       [0.00093191, 0.03666364, 0.01328427, ..., 0.0007506 , 0.00180683,\n",
       "        0.00059028],\n",
       "       [0.3868227 , 0.01950631, 0.03820753, ..., 0.00896966, 0.00716046,\n",
       "        0.00775825],\n",
       "       ...,\n",
       "       [0.41121054, 0.05954427, 0.08266822, ..., 0.01597749, 0.00971078,\n",
       "        0.01363079],\n",
       "       [0.03752485, 0.11114152, 0.10522438, ..., 0.00830431, 0.00964018,\n",
       "        0.00817283],\n",
       "       [0.02251291, 0.53282464, 0.19898446, ..., 0.03661538, 0.02997578,\n",
       "        0.02630852]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:23.868043Z",
     "start_time": "2024-10-16T18:56:23.864109Z"
    }
   },
   "cell_type": "code",
   "source": "X_pca",
   "id": "9fb4590fd856b6ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03915129,  0.25591064, -0.02462468, ..., -0.16029406,\n",
       "         0.0226977 , -0.00068658],\n",
       "       [-0.5633726 , -0.10213798, -0.05474524, ...,  0.02349427,\n",
       "        -0.04247905,  0.01655767],\n",
       "       [ 0.3919805 , -0.02780241, -0.01497065, ...,  0.03296212,\n",
       "         0.01104759, -0.04374397],\n",
       "       ...,\n",
       "       [ 0.41940482,  0.15114141,  0.0469614 , ..., -0.01203577,\n",
       "         0.00685298,  0.16842272],\n",
       "       [ 0.02223373,  0.14428133,  0.12941417, ..., -0.01338233,\n",
       "         0.11233086,  0.03091502],\n",
       "       [-0.08598788,  0.40875558,  0.19965279, ...,  0.06390673,\n",
       "         0.004993  ,  0.03752816]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:26.625438Z",
     "start_time": "2024-10-16T18:56:26.608430Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Reconstruction error for the autoencoder: {tf.reduce_mean(mean_squared_error(X_pca, X_latent), axis = -1)}')",
   "id": "c43b07cc3687f8b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error for the autoencoder: 0.018270738422870636\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:27.751770Z",
     "start_time": "2024-10-16T18:56:27.747830Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_model = Model(en_input, en_layer)",
   "id": "fe3d8e802cfb613a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:29.648286Z",
     "start_time": "2024-10-16T18:56:29.641088Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_model.summary()",
   "id": "d56d0ab519b0d5bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70 (280.00 Byte)\n",
      "Trainable params: 70 (280.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:33.828721Z",
     "start_time": "2024-10-16T18:56:33.759744Z"
    }
   },
   "cell_type": "code",
   "source": "X_reduced_latent = encoder_model.predict(X_pca)",
   "id": "5164b762d4cd7914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:34.741160Z",
     "start_time": "2024-10-16T18:56:34.735696Z"
    }
   },
   "cell_type": "code",
   "source": "X_reduced_latent",
   "id": "831298285a31e98e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1242206 , 0.26565158, 1.1441365 , 0.8676859 , 0.59331787],\n",
       "       [1.1745808 , 1.222721  , 1.7721248 , 1.8586228 , 0.23361135],\n",
       "       [0.9614782 , 1.3377264 , 0.2931862 , 0.23041046, 1.6523793 ],\n",
       "       ...,\n",
       "       [1.1956186 , 0.908277  , 0.        , 0.27297217, 1.6069093 ],\n",
       "       [1.0943798 , 0.54879546, 0.60581005, 1.0697554 , 0.8830044 ],\n",
       "       [1.2528572 , 0.04445052, 0.41469407, 1.074172  , 0.06554085]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:35.463109Z",
     "start_time": "2024-10-16T18:56:35.449273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Saving the 5 latent features as a separate csv_file for testing purposes\n",
    "pd.DataFrame(X_reduced_latent).to_csv('5_Latent_Space_X_Features.csv')"
   ],
   "id": "d51a60ec763a6d20",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Train-Val-Test split**",
   "id": "5b3f4cc5fc999087"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:48.150865Z",
     "start_time": "2024-10-16T18:56:48.135541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X_reduced_latent, y, test_size = 0.3, random_state = 42)"
   ],
   "id": "7e27c566a2a98c0c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:48.590017Z",
     "start_time": "2024-10-16T18:56:48.586820Z"
    }
   },
   "cell_type": "code",
   "source": "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.3, random_state = 42)",
   "id": "3280ab1710d52af",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Using this for a demo classification**",
   "id": "b1ff68f23008b60c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:53.494786Z",
     "start_time": "2024-10-16T18:56:53.444837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ANN binary classifier\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "input_layer = Input(shape = (X_reduced_latent.shape[1]))\n",
    "fc_1 = Dense(128, activation = 'relu')(input_layer)\n",
    "dp_1 = Dropout(0.5)(fc_1)\n",
    "bn_1 = BatchNormalization(momentum = 0.8)(dp_1)\n",
    "fc_2 = Dense(256, activation = 'relu')(dp_1)\n",
    "dp_2 = Dropout(0.2)(fc_2)\n",
    "bn_2 = BatchNormalization(momentum = 0.8)(dp_2)\n",
    "classifier_layer = Dense(1, activation = 'sigmoid')(bn_2)\n",
    "ann_classifier_model = Model(input_layer, classifier_layer)"
   ],
   "id": "ab68cfe37d8153b0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:54.958618Z",
     "start_time": "2024-10-16T18:56:54.952120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "ann_classifier_model.compile(loss = BinaryCrossentropy(), optimizer = Adam(learning_rate= 0.001), metrics = ['accuracy'])"
   ],
   "id": "227f9543932e762d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:55.523054Z",
     "start_time": "2024-10-16T18:56:55.519217Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "d24c67ea08c40244",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:56.569359Z",
     "start_time": "2024-10-16T18:56:56.559355Z"
    }
   },
   "cell_type": "code",
   "source": "ann_classifier_model.summary()",
   "id": "87c0a8342b2da98d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               768       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35073 (137.00 KB)\n",
      "Trainable params: 34561 (135.00 KB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:57.149063Z",
     "start_time": "2024-10-16T18:56:57.145519Z"
    }
   },
   "cell_type": "code",
   "source": "X_val.shape",
   "id": "ccb0ec2299e9b51c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:56:59.157034Z",
     "start_time": "2024-10-16T18:56:59.153238Z"
    }
   },
   "cell_type": "code",
   "source": "X_test.shape",
   "id": "bc855a39dae1595c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T18:05:41.366803Z",
     "start_time": "2024-10-15T18:05:41.357642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Saving the train, test and validation sets as csv files for testing purposes\n",
    "pd.DataFrame(X_train).to_csv('5_latent_X_train.csv')\n",
    "pd.DataFrame(X_test).to_csv('5_latent_X_test.csv')\n",
    "pd.DataFrame(X_val).to_csv('5_latent_X_val.csv')\n",
    "pd.DataFrame(y_train).to_csv('5_latent_y_train.csv')\n",
    "pd.DataFrame(y_test).to_csv('5_latent_y_test.csv')\n",
    "pd.DataFrame(y_val).to_csv('5_latent_y_val.csv')"
   ],
   "id": "603a1032d3d19e8d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:08.880307Z",
     "start_time": "2024-10-16T18:57:06.598195Z"
    }
   },
   "cell_type": "code",
   "source": "history_ann = ann_classifier_model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 100, callbacks = [lrs, es])",
   "id": "97b8127d6233c2be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 17ms/step - loss: 0.9192 - accuracy: 0.4778 - val_loss: 0.6506 - val_accuracy: 0.5926 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8113 - accuracy: 0.4877 - val_loss: 0.6160 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8267 - accuracy: 0.5123 - val_loss: 0.5801 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7421 - accuracy: 0.5616 - val_loss: 0.5515 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.5911 - val_loss: 0.5431 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7802 - accuracy: 0.5271 - val_loss: 0.5374 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7561 - accuracy: 0.5468 - val_loss: 0.5367 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.5468 - val_loss: 0.5330 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.6453 - val_loss: 0.5186 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7425 - accuracy: 0.5567 - val_loss: 0.5102 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.6207 - val_loss: 0.5165 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7306 - accuracy: 0.5813 - val_loss: 0.5149 - val_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.5813 - val_loss: 0.5235 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7064 - accuracy: 0.5764 - val_loss: 0.5195 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7639 - accuracy: 0.5369 - val_loss: 0.5140 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.6355 - val_loss: 0.5177 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.6010 - val_loss: 0.5239 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7248 - accuracy: 0.5714 - val_loss: 0.5199 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7196 - accuracy: 0.5813 - val_loss: 0.5421 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7459 - accuracy: 0.4926 - val_loss: 0.5360 - val_accuracy: 0.6296 - lr: 0.0010\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:12.119215Z",
     "start_time": "2024-10-16T18:57:12.116104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ],
   "id": "490d635f367b50b7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:13.143074Z",
     "start_time": "2024-10-16T18:57:13.137332Z"
    }
   },
   "cell_type": "code",
   "source": "lr.fit(X_train, y_train)",
   "id": "adfb7a7c506819b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:14.765502Z",
     "start_time": "2024-10-16T18:57:14.757613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, lr.predict(X_val)))"
   ],
   "id": "761bc6aef2fadb23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.65      0.85      0.73        13\n",
      "\n",
      "    accuracy                           0.70        27\n",
      "   macro avg       0.72      0.71      0.70        27\n",
      "weighted avg       0.73      0.70      0.70        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:15.954522Z",
     "start_time": "2024-10-16T18:57:15.932292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec = DecisionTreeClassifier()\n",
    "dec.fit(X_train, y_train)"
   ],
   "id": "70c645161b464829",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:17.055388Z",
     "start_time": "2024-10-16T18:57:17.047001Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_val, dec.predict(X_val)))",
   "id": "b3c3e99cf6c5f0b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.43      0.52        14\n",
      "           1       0.56      0.77      0.65        13\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.61      0.60      0.58        27\n",
      "weighted avg       0.61      0.59      0.58        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Hyperparameter Tuning for Logistic Regression**",
   "id": "a3ccbce78b0c1b63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:22.326434Z",
     "start_time": "2024-10-16T18:57:22.113079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lr_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
    "lr_1 = LogisticRegression()\n",
    "gscv = GridSearchCV(param_grid = lr_param_grid, estimator = lr_1, cv = 5)\n",
    "gscv.fit(X_train, y_train)"
   ],
   "id": "ec47e3fdd365f0d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'saga']})"
      ],
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, solver=&#x27;saga&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:23.588600Z",
     "start_time": "2024-10-16T18:57:23.585767Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Best params for Logistic Regression: {gscv.best_params_}')",
   "id": "1f5e736ee62c0ea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:34.187051Z",
     "start_time": "2024-10-16T18:57:34.181898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_1 = LogisticRegression(C = 0.1, penalty = 'l2', solver = 'saga')\n",
    "lr_1.fit(X_train, y_train)"
   ],
   "id": "e9e8d3cf70d799c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='saga')"
      ],
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:36.180961Z",
     "start_time": "2024-10-16T18:57:36.174398Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_val, lr_1.predict(X_val)))",
   "id": "577a5290afc2923e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64        14\n",
      "           1       0.63      0.92      0.75        13\n",
      "\n",
      "    accuracy                           0.70        27\n",
      "   macro avg       0.75      0.71      0.69        27\n",
      "weighted avg       0.76      0.70      0.69        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Directly using Autoencoders without dimensionality reduction using PCA**",
   "id": "1c322fc35bc51129"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:39.799551Z",
     "start_time": "2024-10-16T18:57:39.788895Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "ca5f5e6e1c5a3a66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     GE_FOXA1  GE_CTNNB1  GE_NKX3-1    GE_ATM   GE_SPOP  GE_ZMYM3   GE_BRAF  \\\n",
       "0    0.602396   0.875180   0.652366  0.725424  0.485713  0.650304  0.398619   \n",
       "1    0.555186   0.384184   0.706125  0.374939  0.384733  0.527966  0.231899   \n",
       "2    0.617020   0.792797   0.481580  0.664329  0.501783  0.696835  0.373817   \n",
       "3    0.478407   0.786356   0.568205  0.838920  0.610479  0.889998  0.498159   \n",
       "4    0.377998   0.824718   0.504132  0.611074  0.470017  0.428205  0.292625   \n",
       "..        ...        ...        ...       ...       ...       ...       ...   \n",
       "285  0.100142   0.781156   0.000000  1.000000  0.346003  0.687155  0.230994   \n",
       "286  0.624984   0.860459   0.753073  0.688023  0.427905  0.716040  0.389102   \n",
       "287  0.642609   0.878522   0.668838  0.722636  0.461165  0.703648  0.466096   \n",
       "288  0.535638   0.851672   0.606659  0.667384  0.350445  0.699619  0.382227   \n",
       "289  0.671103   0.809819   0.773450  0.742236  0.466585  0.871814  0.477740   \n",
       "\n",
       "     CNA_FOXA1  CNA_CTNNB1  CNA_PTEN  ...   DM_BRAF  MutSig_(Q-value)_TP53  \\\n",
       "0     0.351251    0.540445  0.683951  ...  0.248904               0.003448   \n",
       "1     0.373873    0.699505  0.410377  ...  0.136454               0.003448   \n",
       "2     0.360982    0.523447  0.553580  ...  0.182826               0.003448   \n",
       "3     0.356812    0.516999  0.644938  ...  0.192746               0.003448   \n",
       "4     0.356812    0.519343  0.635062  ...  0.319159               0.003448   \n",
       "..         ...         ...       ...  ...       ...                    ...   \n",
       "285   0.356812    0.519343  0.637037  ...  0.442787               0.003448   \n",
       "286   0.356812    0.517585  0.639506  ...  0.398802               0.003448   \n",
       "287   0.332607    0.467498  0.612923  ...  0.145212               0.003448   \n",
       "288   0.357739    0.519930  0.644444  ...  0.170628               0.003448   \n",
       "289   0.351251    0.520516  0.610370  ...  0.147778               0.003448   \n",
       "\n",
       "     MutSig_(Q-value)_SPOP  MutSig_(Q-value)_FOXA1  Mut_TP53  Mut_SPOP  \\\n",
       "0                 0.003448                0.003448  0.003448  0.003448   \n",
       "1                 0.003448                0.003448  0.003448  0.003448   \n",
       "2                 0.003448                0.003448  0.003448  0.003448   \n",
       "3                 0.003448                0.003448  0.003448  0.003448   \n",
       "4                 0.003448                0.003448  0.003448  0.003448   \n",
       "..                     ...                     ...       ...       ...   \n",
       "285               0.003448                0.003448  0.003448  0.003448   \n",
       "286               0.003448                0.003448  0.003448  0.003448   \n",
       "287               0.003448                0.003448  0.003448  0.003448   \n",
       "288               0.003448                0.003448  0.003448  0.003448   \n",
       "289               0.003448                0.003448  0.003448  0.003448   \n",
       "\n",
       "     Mut_FOXA1  Freq_TP53  Freq_SPOP  Freq_FOXA1  \n",
       "0     0.003448   0.003448   0.003448    0.003448  \n",
       "1     0.003448   0.003448   0.003448    0.003448  \n",
       "2     0.003448   0.003448   0.003448    0.003448  \n",
       "3     0.003448   0.003448   0.003448    0.003448  \n",
       "4     0.003448   0.003448   0.003448    0.003448  \n",
       "..         ...        ...        ...         ...  \n",
       "285   0.003448   0.003448   0.003448    0.003448  \n",
       "286   0.003448   0.003448   0.003448    0.003448  \n",
       "287   0.003448   0.003448   0.003448    0.003448  \n",
       "288   0.003448   0.003448   0.003448    0.003448  \n",
       "289   0.003448   0.003448   0.003448    0.003448  \n",
       "\n",
       "[290 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GE_FOXA1</th>\n",
       "      <th>GE_CTNNB1</th>\n",
       "      <th>GE_NKX3-1</th>\n",
       "      <th>GE_ATM</th>\n",
       "      <th>GE_SPOP</th>\n",
       "      <th>GE_ZMYM3</th>\n",
       "      <th>GE_BRAF</th>\n",
       "      <th>CNA_FOXA1</th>\n",
       "      <th>CNA_CTNNB1</th>\n",
       "      <th>CNA_PTEN</th>\n",
       "      <th>...</th>\n",
       "      <th>DM_BRAF</th>\n",
       "      <th>MutSig_(Q-value)_TP53</th>\n",
       "      <th>MutSig_(Q-value)_SPOP</th>\n",
       "      <th>MutSig_(Q-value)_FOXA1</th>\n",
       "      <th>Mut_TP53</th>\n",
       "      <th>Mut_SPOP</th>\n",
       "      <th>Mut_FOXA1</th>\n",
       "      <th>Freq_TP53</th>\n",
       "      <th>Freq_SPOP</th>\n",
       "      <th>Freq_FOXA1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.875180</td>\n",
       "      <td>0.652366</td>\n",
       "      <td>0.725424</td>\n",
       "      <td>0.485713</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.540445</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248904</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555186</td>\n",
       "      <td>0.384184</td>\n",
       "      <td>0.706125</td>\n",
       "      <td>0.374939</td>\n",
       "      <td>0.384733</td>\n",
       "      <td>0.527966</td>\n",
       "      <td>0.231899</td>\n",
       "      <td>0.373873</td>\n",
       "      <td>0.699505</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136454</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617020</td>\n",
       "      <td>0.792797</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.501783</td>\n",
       "      <td>0.696835</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.523447</td>\n",
       "      <td>0.553580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182826</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478407</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>0.568205</td>\n",
       "      <td>0.838920</td>\n",
       "      <td>0.610479</td>\n",
       "      <td>0.889998</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.516999</td>\n",
       "      <td>0.644938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192746</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377998</td>\n",
       "      <td>0.824718</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.611074</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.428205</td>\n",
       "      <td>0.292625</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.635062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319159</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.100142</td>\n",
       "      <td>0.781156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.230994</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.624984</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.688023</td>\n",
       "      <td>0.427905</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.389102</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.517585</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398802</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.642609</td>\n",
       "      <td>0.878522</td>\n",
       "      <td>0.668838</td>\n",
       "      <td>0.722636</td>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.703648</td>\n",
       "      <td>0.466096</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145212</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.535638</td>\n",
       "      <td>0.851672</td>\n",
       "      <td>0.606659</td>\n",
       "      <td>0.667384</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>0.699619</td>\n",
       "      <td>0.382227</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.519930</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170628</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.671103</td>\n",
       "      <td>0.809819</td>\n",
       "      <td>0.773450</td>\n",
       "      <td>0.742236</td>\n",
       "      <td>0.466585</td>\n",
       "      <td>0.871814</td>\n",
       "      <td>0.477740</td>\n",
       "      <td>0.351251</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.610370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:46.186074Z",
     "start_time": "2024-10-16T18:57:46.181586Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "de6108b44995da39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "285    0\n",
       "286    0\n",
       "287    1\n",
       "288    0\n",
       "289    0\n",
       "Name: Gleason_Score, Length: 290, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:49.015964Z",
     "start_time": "2024-10-16T18:57:48.953598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Deep Autoencoder neural network\n",
    "input_dim = X.shape[1]\n",
    "encoding_dim = 13\n",
    "en_input = Input(shape = (input_dim, ))\n",
    "en_fc_1 = Dense(64, activation = 'relu')(en_input)\n",
    "en_fc_2 = Dense(32, activation = 'relu')(en_fc_1)\n",
    "encoder_layer = Dense(encoding_dim, activation = 'relu')(en_fc_2)\n",
    "dc_fc_1 = Dense(32, activation = 'relu')(encoder_layer)\n",
    "dc_fc_2 = Dense(64, activation = 'relu')(dc_fc_1)\n",
    "decoder_layer = Dense(input_dim, activation = 'sigmoid')(dc_fc_2)\n",
    "ae_model = Model(en_input, decoder_layer)\n",
    "ae_model.summary()"
   ],
   "id": "3ed52e068ba8e0e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 31)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                2048      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 13)                429       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                448       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 31)                2015      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9132 (35.67 KB)\n",
      "Trainable params: 9132 (35.67 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:57:51.270181Z",
     "start_time": "2024-10-16T18:57:51.260485Z"
    }
   },
   "cell_type": "code",
   "source": "ae_model.compile(loss = mean_squared_error, optimizer = Adam(learning_rate = 0.001))",
   "id": "1e708df5844c2520",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:58:03.478861Z",
     "start_time": "2024-10-16T18:57:52.469715Z"
    }
   },
   "cell_type": "code",
   "source": "history_ae = ae_model.fit(X, X, epochs = 1000, validation_split = 0.2, callbacks = [lrs, es])",
   "id": "face9ef1e2205cfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 0.1126 - val_loss: 0.1086 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1023 - val_loss: 0.0925 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0811 - val_loss: 0.0641 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0501 - val_loss: 0.0349 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0230 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0132 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0115 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0102 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0082 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0073 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0073 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Getting the latent space extraction from the encoder network**",
   "id": "3938d5b1e4dade3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:58:18.535619Z",
     "start_time": "2024-10-16T18:58:18.530324Z"
    }
   },
   "cell_type": "code",
   "source": "e_model = Model(en_input, encoder_layer)",
   "id": "da840a17c081a64a",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:58:19.776176Z",
     "start_time": "2024-10-16T18:58:19.707212Z"
    }
   },
   "cell_type": "code",
   "source": "X_latent_rep = e_model.predict(X)",
   "id": "c5eb4c5d8b18615e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:58:22.928044Z",
     "start_time": "2024-10-16T18:58:22.923440Z"
    }
   },
   "cell_type": "code",
   "source": "X_latent_rep",
   "id": "c7597bf18ea0ad22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0996327, 2.1050708, 4.861546 , ..., 4.9278517, 3.389273 ,\n",
       "        0.       ],\n",
       "       [4.39453  , 1.491024 , 4.633244 , ..., 3.526757 , 2.9620628,\n",
       "        0.       ],\n",
       "       [2.846981 , 1.4760243, 4.5338335, ..., 3.8570526, 2.5805912,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [2.6475654, 1.5444065, 4.800531 , ..., 4.2151246, 2.9763248,\n",
       "        0.       ],\n",
       "       [3.4856834, 1.3742073, 5.253157 , ..., 4.2817254, 3.5131304,\n",
       "        0.       ],\n",
       "       [3.789487 , 1.6757149, 5.68583  , ..., 5.1461673, 4.2301707,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:00:36.445629Z",
     "start_time": "2024-10-16T19:00:36.440659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pd.DataFrame(X_latent_rep).to_csv('13_latent_X.csv')\n",
    "pd.DataFrame(y).to_csv('Gleason_Scores.csv')"
   ],
   "id": "b1283ec9ba71594b",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now using this 13 feature representation, split the dataset and perform binary classification**",
   "id": "8fde6930293e8ece"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:17.187732Z",
     "start_time": "2024-10-15T17:50:17.184360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train ,X_test, y_train, y_test = train_test_split(X_latent_rep, y, test_size = 0.3, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.3, random_state = 42)"
   ],
   "id": "8a4d1654b7a5c0b9",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:17.230228Z",
     "start_time": "2024-10-15T17:50:17.226212Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_val.shape, X_test.shape",
   "id": "523dbb6f907ae825",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203, 13), (27, 13), (60, 13))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Logistic Regression**",
   "id": "f22fad64a4e46327"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:17.287345Z",
     "start_time": "2024-10-15T17:50:17.280518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ],
   "id": "81192ed01d0ca7bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:17.369763Z",
     "start_time": "2024-10-15T17:50:17.363611Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_val, lr.predict(X_val)))",
   "id": "5c9baec6ed21298b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55        14\n",
      "           1       0.58      0.85      0.69        13\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.66      0.64      0.62        27\n",
      "weighted avg       0.67      0.63      0.61        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:17.501827Z",
     "start_time": "2024-10-15T17:50:17.484377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#ANN Based binary classifier\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "ann_classifier_tryhard = Sequential([Dense(32, activation = 'relu'),\n",
    "                                     Dropout(0.1),\n",
    "                                     Dense(32, activation = 'relu'),\n",
    "                                     BatchNormalization(momentum = 0.8),\n",
    "                                     Dense(64, activation = 'relu'),\n",
    "                                     Dropout(0.1),\n",
    "                                     Dense(128, activation = 'relu'),\n",
    "                                     BatchNormalization(momentum = 0.8),\n",
    "                                     Dense(1, activation = 'sigmoid')\n",
    "                                     ])\n",
    "ann_classifier_tryhard.compile(loss = BinaryCrossentropy(), optimizer = Adam(learning_rate = 0.0001), metrics = ['accuracy'])"
   ],
   "id": "72bb9d2da9c6ad99",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:20.410100Z",
     "start_time": "2024-10-15T17:50:17.550209Z"
    }
   },
   "cell_type": "code",
   "source": "history_tryhard = ann_classifier_tryhard.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 100, callbacks = [lrs, es])",
   "id": "9ba52ab7f6cbcd21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 17ms/step - loss: 0.8801 - accuracy: 0.4581 - val_loss: 0.7017 - val_accuracy: 0.4074 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7436 - accuracy: 0.5419 - val_loss: 0.7100 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7434 - accuracy: 0.5616 - val_loss: 0.7172 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7668 - accuracy: 0.5172 - val_loss: 0.7156 - val_accuracy: 0.4815 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7160 - accuracy: 0.6059 - val_loss: 0.7163 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7915 - accuracy: 0.5813 - val_loss: 0.7119 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8526 - accuracy: 0.4828 - val_loss: 0.6646 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7630 - accuracy: 0.5468 - val_loss: 0.6811 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7412 - accuracy: 0.5271 - val_loss: 0.7026 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.5074 - val_loss: 0.7135 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7165 - accuracy: 0.5714 - val_loss: 0.6814 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7456 - accuracy: 0.5074 - val_loss: 0.7133 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7576 - accuracy: 0.5320 - val_loss: 0.6663 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7665 - accuracy: 0.5813 - val_loss: 0.6803 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6108 - val_loss: 0.6658 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7389 - accuracy: 0.5369 - val_loss: 0.6569 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8063 - accuracy: 0.5025 - val_loss: 0.6496 - val_accuracy: 0.6296 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7454 - accuracy: 0.5567 - val_loss: 0.6510 - val_accuracy: 0.6296 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7421 - accuracy: 0.5911 - val_loss: 0.6514 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.5616 - val_loss: 0.6475 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6059 - val_loss: 0.6697 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7037 - accuracy: 0.5616 - val_loss: 0.6701 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7321 - accuracy: 0.5271 - val_loss: 0.6457 - val_accuracy: 0.6296 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7658 - accuracy: 0.5320 - val_loss: 0.6652 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6865 - accuracy: 0.5911 - val_loss: 0.6643 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7410 - accuracy: 0.5813 - val_loss: 0.6274 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7579 - accuracy: 0.5320 - val_loss: 0.6251 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.5419 - val_loss: 0.6388 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6769 - accuracy: 0.6108 - val_loss: 0.6516 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.5862 - val_loss: 0.6355 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7242 - accuracy: 0.5714 - val_loss: 0.6357 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7206 - accuracy: 0.5616 - val_loss: 0.6505 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.6059 - val_loss: 0.6220 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6010 - val_loss: 0.6243 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7313 - accuracy: 0.5271 - val_loss: 0.6517 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.5911 - val_loss: 0.6293 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5567 - val_loss: 0.6415 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7192 - accuracy: 0.5320 - val_loss: 0.6220 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7452 - accuracy: 0.5468 - val_loss: 0.6306 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.6158 - val_loss: 0.6497 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7374 - accuracy: 0.5567 - val_loss: 0.6332 - val_accuracy: 0.6296 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7220 - accuracy: 0.4778 - val_loss: 0.6383 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7242 - accuracy: 0.5665 - val_loss: 0.6344 - val_accuracy: 0.6296 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:50:20.430439Z",
     "start_time": "2024-10-15T17:50:20.429217Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "723398b9bf7d8364",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
